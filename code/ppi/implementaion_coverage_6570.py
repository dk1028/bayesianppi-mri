# -*- coding: utf-8 -*-
"""implementaion_coverage_6570.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L2H7max07qBSBMvcnYsh3z74o8AuvwHj
"""

!pip -q install "pymc>=5,<6"

# ====== Google Drive mount & path ======

CSV_PATH = '/content/drive/MyDrive/age_analysis/autorater_predictions_all2.csv'  # <- use this file

# ====== simulation.py (Colab-ready) ======
import numpy as np
import pandas as pd
import pymc as pm
from tqdm import tqdm
from scipy.stats import t  # for small-n t critical values

# ----------------------------
# 0) Reproducibility settings
# ----------------------------
# Use one global RNG so that the SAME labeled indices are reused across priors
rng = np.random.default_rng(2025)

# 1) Load full data (Google Drive path)
df = pd.read_csv(CSV_PATH)
df['H'] = (df['label'] == 'AD').astype(int)

# Keep BOTH probability and class threshold for different estimators
df['A_prob']  = df['autorater_prediction'].astype(float)           # continuous autorater output in [0,1]
df['A_class'] = (df['autorater_prediction'] >= 0.5).astype(int)    # thresholded at 0.5

# Full-pool size and true g
N      = len(df)
g_true = df['H'].mean()
NA1    = int(df['A_class'].sum())  # number of A_class==1 over the whole pool

# ----------------------------
# 2) Chain-rule Estimator (takes prior α,β)
#     NOTE: This variant uses A_class (K=2 bins) as in your original code.
# ----------------------------
def chain_rule_estimator(labeled_idx, alpha, beta):
    sub = df.iloc[labeled_idx]
    n1 = int((sub['A_class']==1).sum())
    H1 = int(sub.loc[sub['A_class']==1, 'H'].sum())
    n0 = int((sub['A_class']==0).sum())
    H0 = int(sub.loc[sub['A_class']==0, 'H'].sum())

    with pm.Model() as model:
        θA  = pm.Beta('θA',  alpha, beta)
        θH1 = pm.Beta('θH1', alpha, beta)
        θH0 = pm.Beta('θH0', alpha, beta)

        pm.Binomial('obs_A',  N,  θA,  observed=NA1)
        pm.Binomial('obs_H1', n1, θH1, observed=H1)
        pm.Binomial('obs_H0', n0, θH0, observed=H0)

        g = pm.Deterministic('g', θA*θH1 + (1-θA)*θH0)

        idata = pm.sample(
            draws=500, tune=500,
            chains=2, cores=1,
            progressbar=False,
            target_accept=0.9,
            random_seed=12345
        )

    g_samples = idata.posterior['g'].values.flatten()
    return g_samples.mean(), np.quantile(g_samples, [0.025, 0.975])

# ----------------------------
# 3) Naïve Estimator (Beta posterior on H only; takes α,β)
# ----------------------------
def naive_estimator(labeled_idx, alpha, beta):
    sub   = df.iloc[labeled_idx]
    n     = len(sub)
    H_sum = int(sub['H'].sum())
    a, b  = alpha + H_sum, beta + n - H_sum
    samples = np.random.default_rng(123).beta(a, b, size=2000)
    return samples.mean(), np.quantile(samples, [0.025, 0.975])

# ----------------------------
# 4) Difference Estimator (class-thresholded A; matches your original baseline)
#     ĝ = Ā + (H - A_class)̄  with bootstrap CI
# ----------------------------
def difference_estimator(labeled_idx):
    A_bar = df['A_class'].mean()
    resid = df.iloc[labeled_idx]['H'] - df.iloc[labeled_idx]['A_class']
    g_hat = A_bar + resid.mean()

    # Bootstrap CI on the residual mean
    boots = [A_bar + resid.sample(frac=1, replace=True).mean()
             for _ in range(1000)]
    ci = np.quantile(boots, [0.025, 0.975])
    return g_hat, ci

# ----------------------------
# 4.5) PPI (analytic) — formula-based CI using CONTINUOUS A_prob
#      CI: ĝ ± crit * sqrt( Var(A)/N + Var(H−A)/n )
#      * Uses t-crit for small n (n<30) and z-crit otherwise.
#      * A component uses the full pool (N), so Var(A)/N is computed on all rows.
# ----------------------------
def ppi_analytic_estimator(labeled_idx):
    # Full-pool A (continuous probability) mean/variance
    A_all = df['A_prob'].astype(float).values
    N_all = len(A_all)
    A_bar = A_all.mean()
    varA  = A_all.var(ddof=1) if N_all > 1 else 0.0

    # Labeled subset residuals R = H - A_prob
    sub   = df.iloc[labeled_idx]
    R     = (sub['H'].astype(float) - sub['A_prob'].astype(float)).values
    n_lab = len(R)
    r_bar = R.mean() if n_lab > 0 else 0.0
    varR  = R.var(ddof=1) if n_lab > 1 else 0.0

    # Point estimate
    g_hat = A_bar + r_bar

    # Standard error
    se = np.sqrt(varA / max(N_all, 1) + varR / max(n_lab, 1)) if (N_all > 0 and n_lab > 0) else 0.0

    # Critical value: small-n t, else z
    if n_lab >= 30:
        crit = 1.959963984540054  # two-sided 95% z
    else:
        # df = max(n_lab-1,1) to be safe for n_lab in {1,2}
        dfree = max(n_lab - 1, 1)
        crit = t.ppf(0.975, df=dfree)

    ci_lo = g_hat - crit * se
    ci_hi = g_hat + crit * se
    return g_hat, (ci_lo, ci_hi)

# ----------------------------
# 5) Simulation settings
# ----------------------------
nsim        = 50
label_sizes = [10, 20, 40, 80]
priors = [
    {'name':'uniform',  'alpha':1.0,   'beta':1.0},
    {'name':'jeffreys', 'alpha':0.5,   'beta':0.5}
]

# Pre-draw the labeled indices ONCE so that all priors share the same samples
draws_by_nh = {
    nh: [rng.choice(N, size=nh, replace=False) for _ in range(nsim)]
    for nh in label_sizes
}

all_results = []

for prior in priors:
    pname, α, β = prior['name'], prior['alpha'], prior['beta']
    for nh in label_sizes:
        cov_counts = {'chain':0, 'naive':0, 'diff':0, 'ppi':0}
        widths     = {'chain':[], 'naive':[], 'diff':[], 'ppi':[]}

        for s, idx in enumerate(tqdm(draws_by_nh[nh], desc=f"{pname} | labels={nh}")):
            # Chain-rule (CRE)
            m_c, ci_c = chain_rule_estimator(idx, α, β)
            if ci_c[0] <= g_true <= ci_c[1]:
                cov_counts['chain'] += 1
            widths['chain'].append(ci_c[1] - ci_c[0])

            # Naïve
            m_n, ci_n = naive_estimator(idx, α, β)
            if ci_n[0] <= g_true <= ci_n[1]:
                cov_counts['naive'] += 1
            widths['naive'].append(ci_n[1] - ci_n[0])

            # PPI (analytic; continuous A_prob + small-n t)
            m_p, ci_p = ppi_analytic_estimator(idx)
            if ci_p[0] <= g_true <= ci_p[1]:
                cov_counts['ppi'] += 1
            widths['ppi'].append(ci_p[1] - ci_p[0])

            # Difference (thresholded A_class, as in your original baseline)
            m_d, ci_d = difference_estimator(idx)
            if ci_d[0] <= g_true <= ci_d[1]:
                cov_counts['diff'] += 1
            widths['diff'].append(ci_d[1] - ci_d[0])

        all_results.append({
            'prior':     pname,
            'n_labels':  nh,
            'chain_cov': cov_counts['chain']/nsim,
            'chain_w':   float(np.mean(widths['chain'])),
            'naive_cov': cov_counts['naive']/nsim,
            'naive_w':   float(np.mean(widths['naive'])),
            'diff_cov':  cov_counts['diff']/nsim,
            'diff_w':    float(np.mean(widths['diff'])),
            'ppi_cov':   cov_counts['ppi']/nsim,
            'ppi_w':     float(np.mean(widths['ppi'])),
        })

# 6) Save/print results
res_df = pd.DataFrame(all_results)

# If you want to save to Drive, uncomment:
# out_csv = '/content/drive/MyDrive/age_analysis/simulation_results_prior_sensitivity2.csv'
# res_df.to_csv(out_csv, index=False)

print(res_df)